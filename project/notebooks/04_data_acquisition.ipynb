{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6ccba41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded .env — TICKER: AAPL\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import os, json\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(dotenv_path=Path(\"..\") / \".env\")\n",
    "\n",
    "# Directories\n",
    "RAW_DIR = Path(\"..\") / \"data\" / \"raw\"\n",
    "RAW_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def ts():\n",
    "    \"\"\"Timestamp like 20250817-1615 for filenames.\"\"\"\n",
    "    return datetime.now().strftime(\"%Y%m%d-%H%M\")\n",
    "\n",
    "def validate_df(df: pd.DataFrame, required_cols: list[str]) -> dict:\n",
    "    \"\"\"Basic validation report: shape, NA counts, missing required cols.\"\"\"\n",
    "    report = {\"shape\": list(df.shape), \"missing\": {}, \"required_missing\": []}\n",
    "    for c in required_cols:\n",
    "        if c not in df.columns:\n",
    "            report[\"required_missing\"].append(c)\n",
    "    for c in df.columns:\n",
    "        report[\"missing\"][c] = int(df[c].isna().sum())\n",
    "    return report\n",
    "\n",
    "def assert_ok(report: dict):\n",
    "    if report[\"required_missing\"]:\n",
    "        raise ValueError(f\"Missing required columns: {report['required_missing']}\")\n",
    "\n",
    "print(\"Loaded .env — TICKER:\", os.getenv(\"TICKER\", \"<not set>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "917cd48f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pulling daily prices for: AAPL\n",
      "API validation: {\n",
      "  \"shape\": [\n",
      "    250,\n",
      "    8\n",
      "  ],\n",
      "  \"missing\": {\n",
      "    \"date\": 0,\n",
      "    \"open\": 0,\n",
      "    \"high\": 0,\n",
      "    \"low\": 0,\n",
      "    \"close\": 0,\n",
      "    \"volume\": 0,\n",
      "    \"Dividends\": 0,\n",
      "    \"Stock Splits\": 0\n",
      "  },\n",
      "  \"required_missing\": []\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PosixPath('../data/raw/api_yfinance_AAPL_20250817-2321.csv')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "\n",
    "ticker = os.getenv(\"TICKER\", \"AAPL\")\n",
    "print(\"Pulling daily prices for:\", ticker)\n",
    "\n",
    "df = yf.Ticker(ticker).history(period=\"1y\", interval=\"1d\").reset_index()\n",
    "\n",
    "# Standardize column names\n",
    "df = df.rename(columns={\n",
    "    \"Date\": \"date\",\n",
    "    \"Open\": \"open\", \"High\": \"high\", \"Low\": \"low\", \"Close\": \"close\", \"Volume\": \"volume\"\n",
    "})\n",
    "\n",
    "# Dtypes\n",
    "df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "for c in [\"open\",\"high\",\"low\",\"close\"]:\n",
    "    df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
    "df[\"volume\"] = pd.to_numeric(df[\"volume\"], errors=\"coerce\").astype(\"Int64\")\n",
    "\n",
    "# Validate\n",
    "req_cols = [\"date\",\"open\",\"high\",\"low\",\"close\",\"volume\"]\n",
    "report = validate_df(df, req_cols)\n",
    "assert_ok(report)\n",
    "print(\"API validation:\", json.dumps(report, indent=2))\n",
    "\n",
    "# Save\n",
    "api_path = RAW_DIR / f\"api_yfinance_{ticker}_{ts()}.csv\"\n",
    "df.to_csv(api_path, index=False)\n",
    "api_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6652b5d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scrape validation: {\n",
      "  \"shape\": [\n",
      "    503,\n",
      "    5\n",
      "  ],\n",
      "  \"missing\": {\n",
      "    \"Symbol\": 0,\n",
      "    \"Security\": 0,\n",
      "    \"GICS Sector\": 0,\n",
      "    \"GICS Sub-Industry\": 0,\n",
      "    \"Headquarters Location\": 0\n",
      "  },\n",
      "  \"required_missing\": []\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/hc/lx21f3657gz88_xv7kjd578w0000gn/T/ipykernel_41979/3866246347.py:14: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  sp500 = pd.read_html(str(table))[0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PosixPath('../data/raw/scrape_wikipedia_sp500_constituents_20250817-2325.csv')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "URL = \"https://en.wikipedia.org/wiki/List_of_S%26P_500_companies\"\n",
    "headers = {\"User-Agent\": \"Mozilla/5.0 (educational project)\"}\n",
    "\n",
    "resp = requests.get(URL, headers=headers, timeout=30)\n",
    "resp.raise_for_status()\n",
    "\n",
    "soup = BeautifulSoup(resp.text, \"html.parser\")\n",
    "table = soup.find(\"table\", {\"id\": \"constituents\"})\n",
    "\n",
    "# Use pandas to parse the HTML table for resilience\n",
    "sp500 = pd.read_html(str(table))[0]\n",
    "\n",
    "# Keep a consistent subset if present\n",
    "keep = [c for c in [\"Symbol\",\"Security\",\"GICS Sector\",\"GICS Sub-Industry\",\"Headquarters Location\"] if c in sp500.columns]\n",
    "sp500 = sp500[keep].copy() if keep else sp500.copy()\n",
    "\n",
    "# Validate\n",
    "req_cols2 = [\"Symbol\",\"Security\"]\n",
    "report2 = validate_df(sp500, req_cols2)\n",
    "assert_ok(report2)\n",
    "print(\"Scrape validation:\", json.dumps(report2, indent=2))\n",
    "\n",
    "# Save\n",
    "scrape_path = RAW_DIR / f\"scrape_wikipedia_sp500_constituents_{ts()}.csv\"\n",
    "sp500.to_csv(scrape_path, index=False)\n",
    "scrape_path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b3357e",
   "metadata": {},
   "source": [
    "## Assumptions & Risks\n",
    "\n",
    "- Assumes Yahoo Finance remains available and consistent; occasional gaps/adjustments possible  \n",
    "- Wikipedia table structure may change; selectors may need updates  \n",
    "- `.env` is not committed; `.env.example` shared for reproducibility  \n",
    "- Saved raw files are timestamped; later stages should reference a specific snapshot"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "earnings-sentiment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
