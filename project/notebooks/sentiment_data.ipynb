{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "418149c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root: /Users/brian/bootcamp_Brian_Chang/project\n",
      "Raw data:     /Users/brian/bootcamp_Brian_Chang/project/data/raw\n",
      "Processed:    /Users/brian/bootcamp_Brian_Chang/project/data/processed\n"
     ]
    }
   ],
   "source": [
    "import os, datetime as dt\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load secrets\n",
    "load_dotenv()\n",
    "API_KEY = os.getenv(\"ALPHAVANTAGE_API_KEY\")\n",
    "TICKER  = os.getenv(\"TICKER\", \"AAPL\")\n",
    "assert API_KEY, \"Please set ALPHAVANTAGE_API_KEY in your .env\"\n",
    "\n",
    "# Exact window to match your prices file\n",
    "START_DATE = dt.date(2024, 8, 16)\n",
    "END_DATE   = dt.date(2025, 8, 15)\n",
    "\n",
    "# Find project root (folder that contains data/processed)\n",
    "def find_project_root() -> Path:\n",
    "    here = Path.cwd().resolve()\n",
    "    for cand in [here, *here.parents]:\n",
    "        if (cand / \"data\" / \"processed\").exists():\n",
    "            return cand\n",
    "    raise FileNotFoundError(\"Could not locate a 'data/processed' directory above current folder.\")\n",
    "\n",
    "ROOT = Path(\"..\").resolve()\n",
    "RAW  = ROOT / \"data\" / \"raw\";       RAW.mkdir(parents=True, exist_ok=True)\n",
    "PROC = ROOT / \"data\" / \"processed\"; PROC.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def ts():\n",
    "    return dt.datetime.now().strftime(\"%Y%m%d-%H%M\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bdf40fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def month_iter(start_date: dt.date, end_date: dt.date):\n",
    "    \"\"\"Yield (month_start, month_end) for each month overlapping [start_date, end_date].\"\"\"\n",
    "    cur = dt.date(start_date.year, start_date.month, 1)\n",
    "    while cur <= end_date:\n",
    "        if cur.month == 12:\n",
    "            nxt = dt.date(cur.year + 1, 1, 1)\n",
    "        else:\n",
    "            nxt = dt.date(cur.year, cur.month + 1, 1)\n",
    "        m_start, m_end = cur, min(end_date, nxt - dt.timedelta(days=1))\n",
    "        # clip the first month to start_date\n",
    "        if m_start < start_date:\n",
    "            m_start = start_date\n",
    "        yield m_start, m_end\n",
    "        cur = nxt\n",
    "\n",
    "def fetch_alpha_news_sentiment_window(ticker: str, apikey: str, start: dt.date, end: dt.date, limit: int = 2000) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Fetch Alpha Vantage NEWS_SENTIMENT for a given [start,end] window (UTC calendar).\n",
    "    Returns article-level DataFrame with raw fields.\n",
    "    \"\"\"\n",
    "    url = \"https://www.alphavantage.co/query\"\n",
    "    # Alpha Vantage expects YYYYMMDDThhmm (UTC)\n",
    "    time_from = dt.datetime(start.year, start.month, start.day, 0, 0)\n",
    "    time_to   = dt.datetime(end.year,   end.month,   end.day,   23, 59)\n",
    "    params = {\n",
    "        \"function\": \"NEWS_SENTIMENT\",\n",
    "        \"tickers\": ticker,\n",
    "        \"time_from\": time_from.strftime(\"%Y%m%dT%H%M\"),\n",
    "        \"time_to\":   time_to .strftime(\"%Y%m%dT%H%M\"),\n",
    "        \"limit\": str(limit),\n",
    "        \"apikey\": apikey,\n",
    "        \"sort\": \"LATEST\",\n",
    "    }\n",
    "    r = requests.get(url, params=params, timeout=30)\n",
    "    r.raise_for_status()\n",
    "    data = r.json()\n",
    "\n",
    "    feed = data.get(\"feed\", [])\n",
    "    if not feed:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    rows = []\n",
    "    for item in feed:\n",
    "        overall_score = item.get(\"overall_sentiment_score\")\n",
    "        overall_label = item.get(\"overall_sentiment_label\")\n",
    "\n",
    "        # Pull ticker-specific sentiment (if present) for our ticker\n",
    "        tick_info = {\"ticker\": ticker, \"relevance_score\": None,\n",
    "                     \"ticker_sentiment_score\": None, \"ticker_sentiment_label\": None}\n",
    "        for t in item.get(\"ticker_sentiment\", []):\n",
    "            if t.get(\"ticker\") == ticker:\n",
    "                tick_info = {\n",
    "                    \"ticker\": t.get(\"ticker\"),\n",
    "                    \"relevance_score\": float(t.get(\"relevance_score\", 0.0)),\n",
    "                    \"ticker_sentiment_score\": float(t.get(\"ticker_sentiment_score\", 0.0)),\n",
    "                    \"ticker_sentiment_label\": t.get(\"ticker_sentiment_label\"),\n",
    "                }\n",
    "                break\n",
    "\n",
    "        rows.append({\n",
    "            \"time_published\": item.get(\"time_published\"),  # \"YYYYMMDDThhmm\" or \"...hhmmss\"\n",
    "            \"source\": item.get(\"source\"),\n",
    "            \"title\": item.get(\"title\"),\n",
    "            \"url\": item.get(\"url\"),\n",
    "            \"overall_sentiment_score\": float(overall_score) if overall_score is not None else None,\n",
    "            \"overall_sentiment_label\": overall_label,\n",
    "            **tick_info\n",
    "        })\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "\n",
    "    # Robust timestamp parsing (seconds first, then minutes, then free parser)\n",
    "    pu = pd.to_datetime(df[\"time_published\"], format=\"%Y%m%dT%H%M%S\", errors=\"coerce\", utc=True)\n",
    "    m = pu.isna()\n",
    "    if m.any():\n",
    "        pu2 = pd.to_datetime(df.loc[m, \"time_published\"], format=\"%Y%m%dT%H%M\", errors=\"coerce\", utc=True)\n",
    "        pu.loc[m] = pu2\n",
    "    m2 = pu.isna()\n",
    "    if m2.any():\n",
    "        pu3 = pd.to_datetime(df.loc[m2, \"time_published\"], errors=\"coerce\", utc=True)\n",
    "        pu.loc[m2] = pu3\n",
    "\n",
    "    df[\"published_utc\"] = pu\n",
    "    try:\n",
    "        df[\"published_ny\"] = df[\"published_utc\"].dt.tz_convert(\"America/New_York\")\n",
    "    except Exception:\n",
    "        df[\"published_ny\"] = df[\"published_utc\"].dt.tz_convert(\"US/Eastern\")\n",
    "    df[\"date_ny\"]  = df[\"published_ny\"].dt.date\n",
    "    df[\"date_utc\"] = df[\"published_utc\"].dt.date\n",
    "\n",
    "    # Coerce numeric\n",
    "    for col in [\"relevance_score\",\"ticker_sentiment_score\",\"overall_sentiment_score\"]:\n",
    "        if col in df.columns:\n",
    "            df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "05c37d37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP 200\n",
      "Keys present: ['items', 'sentiment_score_definition', 'relevance_score_definition', 'feed']\n",
      "Feed articles: 50\n",
      "First item fields: ['title', 'url', 'time_published', 'authors', 'summary', 'banner_image', 'source', 'category_within_source', 'source_domain', 'topics', 'overall_sentiment_score', 'overall_sentiment_label', 'ticker_sentiment']\n",
      "Sample time_published: 20250314T214510\n"
     ]
    }
   ],
   "source": [
    "import datetime as dt, requests, pandas as pd, os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "API_KEY = os.getenv(\"ALPHAVANTAGE_API_KEY\")\n",
    "TICKER  = os.getenv(\"TICKER\", \"AAPL\")\n",
    "assert API_KEY, \"Set ALPHAVANTAGE_API_KEY in .env\"\n",
    "\n",
    "def debug_window(ticker, start_date: dt.date, end_date: dt.date):\n",
    "    url = \"https://www.alphavantage.co/query\"\n",
    "    time_from = dt.datetime(start_date.year, start_date.month, start_date.day, 0, 0)\n",
    "    time_to   = dt.datetime(end_date.year,   end_date.month,   end_date.day,   23, 59)\n",
    "    params = {\n",
    "        \"function\": \"NEWS_SENTIMENT\",\n",
    "        \"tickers\": ticker,\n",
    "        \"time_from\": time_from.strftime(\"%Y%m%dT%H%M\"),\n",
    "        \"time_to\":   time_to.strftime(\"%Y%m%dT%H%M\"),\n",
    "        \"limit\": \"200\",\n",
    "        \"apikey\": API_KEY,\n",
    "        \"sort\": \"LATEST\",\n",
    "    }\n",
    "    r = requests.get(url, params=params, timeout=30)\n",
    "    data = r.json()\n",
    "    print(\"HTTP\", r.status_code)\n",
    "    print(\"Keys present:\", list(data.keys()))\n",
    "    if \"Note\" in data:\n",
    "        print(\"NOTE from API:\", data[\"Note\"])\n",
    "    if \"Information\" in data:\n",
    "        print(\"INFO from API:\", data[\"Information\"])\n",
    "    feed = data.get(\"feed\", [])\n",
    "    print(f\"Feed articles: {len(feed)}\")\n",
    "    if feed:\n",
    "        print(\"First item fields:\", list(feed[0].keys()))\n",
    "        print(\"Sample time_published:\", feed[0].get(\"time_published\"))\n",
    "    return data\n",
    "\n",
    "# Try a 2-week window near the middle of your range:\n",
    "_ = debug_window(TICKER, dt.date(2025, 3, 1), dt.date(2025, 3, 14))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3cde5e4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Articles fetched (deduped): 650\n",
      "NY date range: 2024-08-28 → 2025-08-15\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time_published</th>\n",
       "      <th>source</th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>overall_sentiment_score</th>\n",
       "      <th>overall_sentiment_label</th>\n",
       "      <th>ticker</th>\n",
       "      <th>relevance_score</th>\n",
       "      <th>ticker_sentiment_score</th>\n",
       "      <th>ticker_sentiment_label</th>\n",
       "      <th>published_utc</th>\n",
       "      <th>published_ny</th>\n",
       "      <th>date_ny</th>\n",
       "      <th>date_utc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20240831T102400</td>\n",
       "      <td>Motley Fool</td>\n",
       "      <td>Warren Buffett Sold Apple Stock, but These Bil...</td>\n",
       "      <td>https://www.fool.com/investing/2024/08/31/warr...</td>\n",
       "      <td>0.298569</td>\n",
       "      <td>Somewhat-Bullish</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>0.731795</td>\n",
       "      <td>0.449680</td>\n",
       "      <td>Bullish</td>\n",
       "      <td>2024-08-31 10:24:00+00:00</td>\n",
       "      <td>2024-08-31 06:24:00-04:00</td>\n",
       "      <td>2024-08-31</td>\n",
       "      <td>2024-08-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20240831T101000</td>\n",
       "      <td>Motley Fool</td>\n",
       "      <td>Will TSMC Be Worth More Than Apple by 2030?</td>\n",
       "      <td>https://www.fool.com/investing/2024/08/31/will...</td>\n",
       "      <td>0.258679</td>\n",
       "      <td>Somewhat-Bullish</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>0.449723</td>\n",
       "      <td>0.348895</td>\n",
       "      <td>Somewhat-Bullish</td>\n",
       "      <td>2024-08-31 10:10:00+00:00</td>\n",
       "      <td>2024-08-31 06:10:00-04:00</td>\n",
       "      <td>2024-08-31</td>\n",
       "      <td>2024-08-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20240831T091500</td>\n",
       "      <td>Motley Fool</td>\n",
       "      <td>3 Incredible FAANG Stocks You'll Want to Consi...</td>\n",
       "      <td>https://www.fool.com/investing/2024/08/31/incr...</td>\n",
       "      <td>0.265451</td>\n",
       "      <td>Somewhat-Bullish</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>0.303592</td>\n",
       "      <td>0.254529</td>\n",
       "      <td>Somewhat-Bullish</td>\n",
       "      <td>2024-08-31 09:15:00+00:00</td>\n",
       "      <td>2024-08-31 05:15:00-04:00</td>\n",
       "      <td>2024-08-31</td>\n",
       "      <td>2024-08-31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    time_published       source  \\\n",
       "0  20240831T102400  Motley Fool   \n",
       "1  20240831T101000  Motley Fool   \n",
       "2  20240831T091500  Motley Fool   \n",
       "\n",
       "                                               title  \\\n",
       "0  Warren Buffett Sold Apple Stock, but These Bil...   \n",
       "1        Will TSMC Be Worth More Than Apple by 2030?   \n",
       "2  3 Incredible FAANG Stocks You'll Want to Consi...   \n",
       "\n",
       "                                                 url  overall_sentiment_score  \\\n",
       "0  https://www.fool.com/investing/2024/08/31/warr...                 0.298569   \n",
       "1  https://www.fool.com/investing/2024/08/31/will...                 0.258679   \n",
       "2  https://www.fool.com/investing/2024/08/31/incr...                 0.265451   \n",
       "\n",
       "  overall_sentiment_label ticker  relevance_score  ticker_sentiment_score  \\\n",
       "0        Somewhat-Bullish   AAPL         0.731795                0.449680   \n",
       "1        Somewhat-Bullish   AAPL         0.449723                0.348895   \n",
       "2        Somewhat-Bullish   AAPL         0.303592                0.254529   \n",
       "\n",
       "  ticker_sentiment_label             published_utc              published_ny  \\\n",
       "0                Bullish 2024-08-31 10:24:00+00:00 2024-08-31 06:24:00-04:00   \n",
       "1       Somewhat-Bullish 2024-08-31 10:10:00+00:00 2024-08-31 06:10:00-04:00   \n",
       "2       Somewhat-Bullish 2024-08-31 09:15:00+00:00 2024-08-31 05:15:00-04:00   \n",
       "\n",
       "      date_ny    date_utc  \n",
       "0  2024-08-31  2024-08-31  \n",
       "1  2024-08-31  2024-08-31  \n",
       "2  2024-08-31  2024-08-31  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frames = []\n",
    "for m_start, m_end in month_iter(START_DATE, END_DATE):\n",
    "    dfm = fetch_alpha_news_sentiment_window(TICKER, API_KEY, m_start, m_end, limit=200)\n",
    "    if not dfm.empty:\n",
    "        frames.append(dfm)\n",
    "\n",
    "articles = (pd.concat(frames, ignore_index=True)\n",
    "            if frames else\n",
    "            pd.DataFrame(columns=[\n",
    "                \"time_published\",\"source\",\"title\",\"url\",\"overall_sentiment_score\",\"overall_sentiment_label\",\n",
    "                \"ticker\",\"relevance_score\",\"ticker_sentiment_score\",\"ticker_sentiment_label\",\n",
    "                \"published_utc\",\"published_ny\",\"date_ny\",\"date_utc\"\n",
    "            ]))\n",
    "\n",
    "# Drop duplicates by (url, time_published)\n",
    "if not articles.empty:\n",
    "    articles = articles.drop_duplicates(subset=[\"url\",\"time_published\"]).reset_index(drop=True)\n",
    "\n",
    "# Clip to window by NY date (safety)\n",
    "if not articles.empty:\n",
    "    mask = (articles[\"date_ny\"] >= START_DATE) & (articles[\"date_ny\"] <= END_DATE)\n",
    "    articles = articles.loc[mask].reset_index(drop=True)\n",
    "\n",
    "print(\"Articles fetched (deduped):\", len(articles))\n",
    "if not articles.empty:\n",
    "    print(\"NY date range:\", articles[\"date_ny\"].min(), \"→\", articles[\"date_ny\"].max())\n",
    "\n",
    "articles.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3eb9edd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved raw articles → /Users/brian/bootcamp_Brian_Chang/project/data/raw/sentiment_alpha_articles_AAPL_20250823-1041.csv\n"
     ]
    }
   ],
   "source": [
    "raw_path = RAW / f\"sentiment_alpha_articles_{TICKER}_{ts()}.csv\"\n",
    "articles.to_csv(raw_path, index=False)\n",
    "print(\"Saved raw articles →\", raw_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a495eacc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Daily rows: 53\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticker</th>\n",
       "      <th>date</th>\n",
       "      <th>articles</th>\n",
       "      <th>sent_mean</th>\n",
       "      <th>sent_overall_mean</th>\n",
       "      <th>sent_weighted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2024-08-28</td>\n",
       "      <td>13</td>\n",
       "      <td>0.131668</td>\n",
       "      <td>0.207986</td>\n",
       "      <td>0.188072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2024-08-29</td>\n",
       "      <td>13</td>\n",
       "      <td>0.162060</td>\n",
       "      <td>0.230984</td>\n",
       "      <td>0.225318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2024-08-30</td>\n",
       "      <td>18</td>\n",
       "      <td>0.188095</td>\n",
       "      <td>0.232715</td>\n",
       "      <td>0.277089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2024-08-31</td>\n",
       "      <td>6</td>\n",
       "      <td>0.348782</td>\n",
       "      <td>0.244972</td>\n",
       "      <td>0.357171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2024-09-26</td>\n",
       "      <td>6</td>\n",
       "      <td>0.178697</td>\n",
       "      <td>0.274282</td>\n",
       "      <td>0.228993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2024-09-27</td>\n",
       "      <td>13</td>\n",
       "      <td>0.136303</td>\n",
       "      <td>0.220684</td>\n",
       "      <td>0.170078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2024-09-28</td>\n",
       "      <td>11</td>\n",
       "      <td>0.196241</td>\n",
       "      <td>0.215400</td>\n",
       "      <td>0.294228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2024-09-29</td>\n",
       "      <td>4</td>\n",
       "      <td>0.383651</td>\n",
       "      <td>0.288153</td>\n",
       "      <td>0.386503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2024-09-30</td>\n",
       "      <td>16</td>\n",
       "      <td>0.128645</td>\n",
       "      <td>0.192185</td>\n",
       "      <td>0.161520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2024-10-29</td>\n",
       "      <td>12</td>\n",
       "      <td>0.124309</td>\n",
       "      <td>0.232364</td>\n",
       "      <td>0.258968</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ticker        date  articles  sent_mean  sent_overall_mean  sent_weighted\n",
       "0   AAPL  2024-08-28        13   0.131668           0.207986       0.188072\n",
       "1   AAPL  2024-08-29        13   0.162060           0.230984       0.225318\n",
       "2   AAPL  2024-08-30        18   0.188095           0.232715       0.277089\n",
       "3   AAPL  2024-08-31         6   0.348782           0.244972       0.357171\n",
       "4   AAPL  2024-09-26         6   0.178697           0.274282       0.228993\n",
       "5   AAPL  2024-09-27        13   0.136303           0.220684       0.170078\n",
       "6   AAPL  2024-09-28        11   0.196241           0.215400       0.294228\n",
       "7   AAPL  2024-09-29         4   0.383651           0.288153       0.386503\n",
       "8   AAPL  2024-09-30        16   0.128645           0.192185       0.161520\n",
       "9   AAPL  2024-10-29        12   0.124309           0.232364       0.258968"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def aggregate_daily_sentiment_strong(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Aggregate article-level sentiment to daily per ticker (NY market date).\n",
    "    - Use ticker_sentiment_score where available; else fall back to overall_sentiment_score.\n",
    "    - Use relevance_score as weight; else weight=1.\n",
    "    - Keep daily rows sorted and tidy.\n",
    "    \"\"\"\n",
    "    if df.empty:\n",
    "        return pd.DataFrame(columns=[\"ticker\",\"date\",\"articles\",\"sent_weighted\",\"sent_mean\",\"sent_overall_mean\"])\n",
    "\n",
    "    g = df.copy()\n",
    "    if \"ticker\" not in g.columns:\n",
    "        g[\"ticker\"] = TICKER\n",
    "\n",
    "    # Fallback score and weight\n",
    "    g[\"score\"] = g[\"ticker_sentiment_score\"].where(g[\"ticker_sentiment_score\"].notna(),\n",
    "                                                   g[\"overall_sentiment_score\"])\n",
    "    g[\"w\"]     = g[\"relevance_score\"].fillna(1.0)\n",
    "    g[\"wscore\"]= g[\"w\"] * g[\"score\"]\n",
    "\n",
    "    # Require a usable date key (NY dates preferred)\n",
    "    date_key = \"date_ny\" if \"date_ny\" in g.columns and g[\"date_ny\"].notna().any() else \"date_utc\"\n",
    "    g = g[~g[date_key].isna()].copy()\n",
    "\n",
    "    daily = (g.groupby([\"ticker\", date_key])\n",
    "               .agg(\n",
    "                   articles=(\"score\",\"size\"),\n",
    "                   wscore_sum=(\"wscore\",\"sum\"),\n",
    "                   w_sum=(\"w\",\"sum\"),\n",
    "                   sent_mean=(\"score\",\"mean\"),\n",
    "                   sent_overall_mean=(\"overall_sentiment_score\",\"mean\"),\n",
    "               )\n",
    "               .reset_index())\n",
    "\n",
    "    daily[\"sent_weighted\"] = np.where(daily[\"w_sum\"] > 0, daily[\"wscore_sum\"]/daily[\"w_sum\"], np.nan)\n",
    "    daily = (daily\n",
    "             .rename(columns={date_key: \"date\"})\n",
    "             .drop(columns=[\"wscore_sum\",\"w_sum\"])\n",
    "             .sort_values(\"date\")\n",
    "             .reset_index(drop=True))\n",
    "    return daily\n",
    "\n",
    "daily = aggregate_daily_sentiment_strong(articles)\n",
    "print(\"Daily rows:\", len(daily))\n",
    "daily.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5abb9981",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trading days: 250 | with any news: 41\n"
     ]
    }
   ],
   "source": [
    "# Load latest processed prices\n",
    "price_candidates = sorted(PROC.glob(\"prices_preprocessed_*.csv\"), key=lambda p: p.stat().st_mtime, reverse=True)\n",
    "if not price_candidates:\n",
    "    price_candidates = sorted(PROC.glob(\"prices_with_features*.csv\"), key=lambda p: p.stat().st_mtime, reverse=True)\n",
    "assert price_candidates, \"No processed prices CSV found in data/processed/\"\n",
    "prices_path = price_candidates[0]\n",
    "\n",
    "dfp = pd.read_csv(prices_path)\n",
    "dfp[\"date\"] = pd.to_datetime(dfp[\"date\"], errors=\"coerce\", utc=True)\n",
    "try:\n",
    "    dfp[\"date_ny\"] = dfp[\"date\"].dt.tz_convert(\"America/New_York\").dt.date\n",
    "except Exception:\n",
    "    dfp[\"date_ny\"] = dfp[\"date\"].dt.tz_convert(\"US/Eastern\").dt.date\n",
    "\n",
    "# Single-ticker project safeguard\n",
    "if \"ticker\" not in dfp.columns:\n",
    "    dfp[\"ticker\"] = TICKER\n",
    "\n",
    "# Trading-day calendar\n",
    "trading_days = (dfp.loc[(dfp[\"date_ny\"] >= START_DATE) & (dfp[\"date_ny\"] <= END_DATE), [\"ticker\",\"date_ny\"]]\n",
    "                  .dropna().drop_duplicates()\n",
    "                  .rename(columns={\"date_ny\":\"date\"})\n",
    "                  .sort_values(\"date\"))\n",
    "\n",
    "# Join sentiment to trading days\n",
    "sent_aligned = (trading_days.merge(daily, on=[\"ticker\",\"date\"], how=\"left\")\n",
    "                .sort_values(\"date\").reset_index(drop=True))\n",
    "\n",
    "# Fill policies\n",
    "sent_aligned[\"sent_neutral0\"] = sent_aligned[\"sent_weighted\"].fillna(0.0)            # neutral\n",
    "sent_aligned[\"sent_ffill2\"]   = sent_aligned[\"sent_weighted\"].ffill(limit=2).fillna(0.0)  # short persistence\n",
    "\n",
    "print(\"Trading days:\", len(trading_days), \"| with any news:\", sent_aligned[\"sent_weighted\"].notna().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b4e360eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved aligned sentiment → /Users/brian/bootcamp_Brian_Chang/project/data/processed/sentiment_daily_aligned_AAPL_20250823-1109.csv\n"
     ]
    }
   ],
   "source": [
    "aligned_path = PROC / f\"sentiment_daily_aligned_{TICKER}_{ts()}.csv\"\n",
    "sent_aligned.to_csv(aligned_path, index=False)\n",
    "print(\"Saved aligned sentiment →\", aligned_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2234342c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "earnings-sentiment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
