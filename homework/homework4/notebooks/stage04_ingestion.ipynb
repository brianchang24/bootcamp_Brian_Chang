{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a3c1456e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded env — DATA_DIR: ./data | TICKER: AAPL\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import os, sys, json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load .env\n",
    "load_dotenv(dotenv_path=Path(\"..\") / \".env\")  # notebook is under notebooks/, .env is one level up\n",
    "\n",
    "DATA_DIR = Path(\"..\") / \"data\"\n",
    "RAW_DIR = DATA_DIR / \"raw\"\n",
    "RAW_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def ts():\n",
    "    \"\"\"Return a timestamp like 20250817-1615 for filenames.\"\"\"\n",
    "    return datetime.now().strftime(\"%Y%m%d-%H%M\")\n",
    "\n",
    "def validate_df(df: pd.DataFrame, required_cols: list[str]) -> dict:\n",
    "    \"\"\"Basic validation: required columns present, shapes/NA counts.\"\"\"\n",
    "    report = {\"shape\": df.shape, \"missing\": {}, \"required_missing\": []}\n",
    "    for c in required_cols:\n",
    "        if c not in df.columns:\n",
    "            report[\"required_missing\"].append(c)\n",
    "    for c in df.columns:\n",
    "        report[\"missing\"][c] = int(df[c].isna().sum())\n",
    "    return report\n",
    "\n",
    "def assert_ok(report: dict):\n",
    "    \"\"\"Raise if required columns missing.\"\"\"\n",
    "    if report[\"required_missing\"]:\n",
    "        raise ValueError(f\"Missing required columns: {report['required_missing']}\")\n",
    "\n",
    "print(\"Loaded env — DATA_DIR:\", os.getenv(\"DATA_DIR\"), \"| TICKER:\", os.getenv(\"TICKER\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "20a4b627",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pulling daily prices for: AAPL\n",
      "API validation: {\n",
      "  \"shape\": [\n",
      "    250,\n",
      "    8\n",
      "  ],\n",
      "  \"missing\": {\n",
      "    \"date\": 0,\n",
      "    \"open\": 0,\n",
      "    \"high\": 0,\n",
      "    \"low\": 0,\n",
      "    \"close\": 0,\n",
      "    \"volume\": 0,\n",
      "    \"Dividends\": 0,\n",
      "    \"Stock Splits\": 0\n",
      "  },\n",
      "  \"required_missing\": []\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PosixPath('../data/raw/api_yfinance_AAPL_20250817-2248.csv')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "\n",
    "ticker = os.getenv(\"TICKER\", \"AAPL\")\n",
    "print(\"Pulling daily prices for:\", ticker)\n",
    "\n",
    "data = yf.Ticker(ticker).history(period=\"1y\", interval=\"1d\")\n",
    "# move index (DatetimeIndex) to a column for CSV friendliness\n",
    "data = data.reset_index().rename(columns={\"Date\": \"date\", \"Open\":\"open\",\"High\":\"high\",\"Low\":\"low\",\"Close\":\"close\",\"Volume\":\"volume\"})\n",
    "# parse dtypes\n",
    "data[\"date\"] = pd.to_datetime(data[\"date\"])\n",
    "for col in [\"open\",\"high\",\"low\",\"close\"]:\n",
    "    data[col] = pd.to_numeric(data[col], errors=\"coerce\")\n",
    "data[\"volume\"] = pd.to_numeric(data[\"volume\"], errors=\"coerce\").astype(\"Int64\")\n",
    "\n",
    "# validate\n",
    "req_cols = [\"date\",\"open\",\"high\",\"low\",\"close\",\"volume\"]\n",
    "report = validate_df(data, req_cols)\n",
    "assert_ok(report)\n",
    "print(\"API validation:\", json.dumps(report, indent=2))\n",
    "\n",
    "# save\n",
    "api_path = RAW_DIR / f\"api_yfinance_{ticker}_{ts()}.csv\"\n",
    "data.to_csv(api_path, index=False)\n",
    "api_path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b2dbd6c",
   "metadata": {},
   "source": [
    "**Source:**  \n",
    "- Yahoo Finance via `yfinance` Python library  \n",
    "\n",
    "**Parameters:**  \n",
    "- `ticker`: Loaded from `.env` file (example: AAPL)  \n",
    "- `period`: \"1y\" (1 year of data)  \n",
    "- `interval`: \"1d\" (daily frequency)  \n",
    "\n",
    "**Validation Performed:**  \n",
    "- Required columns: `date, open, high, low, close, volume`  \n",
    "- Checked for missing values (all zero above)  \n",
    "- Confirmed dataset shape: 250 rows × 8 columns  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8983b602",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scrape validation: {\n",
      "  \"shape\": [\n",
      "    503,\n",
      "    4\n",
      "  ],\n",
      "  \"missing\": {\n",
      "    \"Symbol\": 0,\n",
      "    \"Security\": 0,\n",
      "    \"GICS Sub-Industry\": 0,\n",
      "    \"Headquarters Location\": 0\n",
      "  },\n",
      "  \"required_missing\": []\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PosixPath('../data/raw/scrape_wikipedia_sp500_constituents_20250817-2258.csv')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "URL = \"https://en.wikipedia.org/wiki/List_of_S%26P_500_companies\"\n",
    "headers = {\"User-Agent\": \"Mozilla/5.0 (educational project)\"}\n",
    "\n",
    "resp = requests.get(URL, headers=headers, timeout=30)\n",
    "resp.raise_for_status()\n",
    "\n",
    "soup = BeautifulSoup(resp.text, \"html.parser\")\n",
    "# The table we want has id=\"constituents\"\n",
    "table = soup.find(\"table\", {\"id\": \"constituents\"})\n",
    "rows = table.find_all(\"tr\")\n",
    "\n",
    "# Parse header\n",
    "header = [th.get_text(strip=True) for th in rows[0].find_all([\"th\",\"td\"])]\n",
    "\n",
    "records = []\n",
    "for r in rows[1:]:\n",
    "    cells = [td.get_text(strip=True) for td in r.find_all([\"td\",\"th\"])]\n",
    "    if len(cells) == len(header):\n",
    "        records.append(cells)\n",
    "\n",
    "scrape_df = pd.DataFrame(records, columns=header)\n",
    "\n",
    "# Keep a small subset of columns commonly present\n",
    "keep = [c for c in [\"Symbol\",\"Security\",\"GICS Sector\",\"GICS Sub-Industry\",\"Headquarters Location\"] if c in scrape_df.columns]\n",
    "scrape_df = scrape_df[keep].copy()\n",
    "\n",
    "# basic validation\n",
    "req_cols = [\"Symbol\",\"Security\"]\n",
    "report2 = validate_df(scrape_df, req_cols)\n",
    "assert_ok(report2)\n",
    "print(\"Scrape validation:\", json.dumps(report2, indent=2))\n",
    "\n",
    "# save\n",
    "scrape_path = RAW_DIR / f\"scrape_wikipedia_sp500_constituents_{ts()}.csv\"\n",
    "scrape_df.to_csv(scrape_path, index=False)\n",
    "scrape_path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b18ecff",
   "metadata": {},
   "source": [
    "**Source:**  \n",
    "- Wikipedia S&P 500 list  (URL: <https://en.wikipedia.org/wiki/List_of_S%26P_500_companies>)\n",
    "\n",
    "**Parameters:**  \n",
    "- Extracted `<table>` element using CSS selectors  \n",
    "- Parsed rows into pandas DataFrame  \n",
    "- Columns standardized to expected names  \n",
    "\n",
    "**Validation Performed:**  \n",
    "- Checked required numeric/text columns exist  \n",
    "- Counted missing values (NA)  \n",
    "- Confirmed shape matches expected rows × columns "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f821c4b6",
   "metadata": {},
   "source": [
    "## Assumptions & Risks\n",
    "\n",
    "- Assumes Yahoo Finance API remains available and consistent  \n",
    "- Assumes scraping selectors will continue to work (site structure unchanged)  \n",
    "- Risk of incomplete or delayed data (weekends, holidays, exchange outages)  \n",
    "- Public website may update irregularly; not guaranteed to be authoritative  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fe-course",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
